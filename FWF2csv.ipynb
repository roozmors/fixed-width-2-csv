{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed width file to csv\n",
    "\n",
    "In this notebook, we first create a Fixed-Width_File (fwf) from an arbitrary dictionary using the configuration given in 'spec.json' file. \n",
    "\n",
    "We consider few data corruption scenarios:\n",
    "\n",
    "1. Length of columns are not equal, i.e. some columns have empty values in some of their cells. This is fixed by fix_dict function.\n",
    "\n",
    "2. Data type in the cell doens't match the input data in the cell. E.g. the column is supposed to be string (indicated in config), but the input data is integer. Function fix_column_type is responsible for fixint this issue. \n",
    "\n",
    "3. Data length is more than what it should be (enforced by config file). If the column is string, we select first n characters. n comes from config file. If it is integer or float, an error is raised as we don't know what could be the correct method to deal with this situation. Another option is to set that cell with corrupted data to a default value (e.g. -1 for int if -1 is not in the range of that column). \n",
    "\n",
    "Then the file is written to a fw file named 'new_file.txt' with proper encoding. \n",
    "\n",
    "Next, the fwf is opened again, and is read line by line. Each line is delimited by a delimiter (which is a comma by default)  and then, it is written to a csv file named 'new_utf8_file.csv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('spec.json','r') as jf:\n",
    "    specs_dict = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': {'length': 5, 'type': str, 'default_value': ''},\n",
       " 'f2': {'length': 12, 'type': str, 'default_value': ''},\n",
       " 'f3': {'length': 3, 'type': str, 'default_value': ''},\n",
       " 'f4': {'length': 2, 'type': str, 'default_value': ''},\n",
       " 'f5': {'length': 13, 'type': str, 'default_value': ''},\n",
       " 'f6': {'length': 7, 'type': str, 'default_value': ''},\n",
       " 'f7': {'length': 10, 'type': str, 'default_value': ''},\n",
       " 'f8': {'length': 13, 'type': str, 'default_value': ''},\n",
       " 'f9': {'length': 20, 'type': str, 'default_value': ''},\n",
       " 'f10': {'length': 13, 'type': str, 'default_value': ''}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict = {col_name:{'length': int(length_val), 'type': str,'default_value' : ''} \n",
    "               for (col_name,length_val) in zip(specs_dict['ColumnNames'],\n",
    "                                                specs_dict['Offsets'])}\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data2 = {\n",
    "    'f1': ['â€™','AB','AAABBB_B'],\n",
    "    'f2': ['cd','CD','CCC_DDD_D'],\n",
    "    'f3': ['ef',1234,'EFFF_FFF'],\n",
    "    'f4': ['gh','GH','GHGHGHGH'],\n",
    "    'f5': ['ij','IJ','IJIJIJIJ'],\n",
    "    'f6': ['kl','KL','KL___KL'],\n",
    "    'f7': ['mn','MN','MN123456MN'],\n",
    "    'f8': ['op','OP','OPOP'],\n",
    "    'f9': ['qr','QR','QRqrQRqr'],\n",
    "    'f10': ['st','ST','STSTstST']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data_type(data_dict, config =config_dict):\n",
    "    data_dict = fix_cols_type(data_dict, config)\n",
    "    data_dict = fix_cols_length(data_dict, config)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix data type\n",
    "\n",
    "Data might have wrong type and length, we check and fix those issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dict(data_dict,config,max_length_data):\n",
    "    \"\"\" This function fills the empty cells (end of the list) with default values from config file\"\"\"\n",
    "    for field_name in data_dict:\n",
    "        if len(data_dict[field_name])<max_length_data:\n",
    "            extesion_list = [config[field_name]['default_value'] for i in range(max_length_data-len(data_dict[field_name])) ]\n",
    "            data_dict[field_name].extend(extesion_list)\n",
    "            \n",
    "    return data_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cols_type(data_dict, config):\n",
    "    \"\"\"If col type is string, change the data to string. If int or float, try to convert\"\"\"\n",
    "    for col_name in config:\n",
    "        if not isinstance(data_dict[col_name],config[col_name]['type']):\n",
    "            if config[col_name]['type'] is str:\n",
    "                data_dict[col_name] = str(data_dict[col_name])\n",
    "            elif config[col_name]['type'] is int:\n",
    "                try:\n",
    "                    data_dict[col_name] = int(dat_dict[col_name])\n",
    "                except:\n",
    "                    print('{} cant be converted into int format'.format(data_dict[col_name]))\n",
    "            elif config[col_name]['type'] is float:\n",
    "                try:\n",
    "                    data_dict[col_name] = float(data_dict[col_name])\n",
    "                except:\n",
    "                    print('{} cant be converted into float format'.format(data_dict[col_name]))\n",
    "            \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cols_length(data_dict,config):\n",
    "    \"\"\"if length of data in a string-type column is greater than it should be (i.e. =length), pick first 'length' values. \n",
    "    If type is boolean, maybe the input is True, or 1 or yes (etc.), then change the output to 1 \n",
    "    data_dict, contains one series of data. \"\"\" \n",
    "#     dct = dict.fromkeys([col_name for col_name in config])\n",
    "#     print(dct)\n",
    "    for col_name in config:\n",
    "        if config[col_name]['type'] is str:\n",
    "            if len(str(data_dict[col_name])) > config[col_name]['length']:\n",
    "                data_dict[col_name] = data_dict[col_name][:config[col_name]['length'] ] # first length characters\n",
    "        elif config[col_name]['type'] is bool:\n",
    "            if data_dict[col_name] in {1,'yes','Yes','YES','True'}:\n",
    "                data_dict[col_name]=1\n",
    "            elif data_dict[col_name] in {0,'no','No','NO','False'}:\n",
    "                data_dict[col_name]=0\n",
    "            else:\n",
    "                raise ValueError(\"{} is not a bolean type).\".format(data_dict[col_name], config[col_name]['length']) )\n",
    "        \n",
    "        else:\n",
    "            if len(str(data_dict[col_name])) > config[col_name]['length']:\n",
    "                raise ValueError(\"{} cannot fit into {} spaces).\".format(data_dict[col_name], config[col_name]['length']))\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_1 = {'f1': 1,'f2': 'ab'}\n",
    "config_0 = {'f1': {'length': '5', 'type': int},'f2': {'length': '12', 'type': str} }\n",
    "config_1 = {'f1': {'length': '5', 'type': float},'f2': {'length': '12', 'type': str} }\n",
    "config_2 = {'f1': {'length': '5', 'type': str},'f2': {'length': '12', 'type': str} }\n",
    "config_3 = {'f1': {'length': '5', 'type': float},'f2': {'length': '12', 'type': int} }\n",
    "config_4 = {'f1': {'length': '5', 'type': bool},'f2': {'length': '12', 'type': str} }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 1, 'f2': 'ab'}\n",
      "{'f1': 1.0, 'f2': 'ab'}\n",
      "{'f1': '1.0', 'f2': 'ab'}\n",
      "ab cant be converted into int format\n",
      "{'f1': 1.0, 'f2': 'ab'}\n",
      "{'f1': 1.0, 'f2': 'ab'}\n"
     ]
    }
   ],
   "source": [
    "print(fix_cols_type(test_case_1,config_0))\n",
    "print(fix_cols_type(test_case_1,config_1))\n",
    "print(fix_cols_type(test_case_1,config_2))\n",
    "print(fix_cols_type(test_case_1,config_3))\n",
    "print(fix_cols_type(test_case_1,config_4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_2 = {'f1': 111,'f2': 'abcde'}\n",
    "config_5 = {'f1': {'length': 5, 'type': int},'f2': {'length': 12, 'type': str} }\n",
    "config_6 = {'f1': {'length': 2, 'type': int},'f2': {'length': 12, 'type': str} }\n",
    "config_7 = {'f1': {'length': 5, 'type': str},'f2': {'length': 3, 'type': str} }\n",
    "\n",
    "test_case_3 = {'f1': True,'f2': 'abcde'}\n",
    "config_8 = {'f1': {'length': 5, 'type': bool},'f2': {'length': 12, 'type': str} }\n",
    "config_9 = {'f1': {'length': 5, 'type': str},'f2': {'length': 12, 'type': str} }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 111, 'f2': 'abcde'}\n",
      "{'f1': 111, 'f2': 'abc'}\n",
      "{'f1': True, 'f2': 'abcde'}\n",
      "{'f1': 'True', 'f2': 'abcde'}\n"
     ]
    }
   ],
   "source": [
    "print(fix_cols_length(test_case_2,config_5))\n",
    "# print(fix_cols_length(test_case_2,config_6))\n",
    "print(fix_cols_length(test_case_2,config_7))\n",
    "print(fix_cols_type(test_case_3,config_8))\n",
    "print(fix_cols_type(test_case_3,config_9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write file to fixed-width-file (fwf)\n",
    "\n",
    "We assume the data we want to write to fwf is stored in a dictioniary of list objects. Each list object, contains 1 or more entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_line(data_dict,config,encoding = 'utf-8'):\n",
    "    \"\"\" Makes new line with provided input (data) using configuration file (config)\"\"\"\n",
    "    frmt = ''\n",
    "    line = \"\".join(['{0:{1}}'.format(data_dict[col_name],config[col_name]['length']) \n",
    "                    for col_name in config])+'\\n'\n",
    "    \n",
    "    line = line.encode(encoding = encoding, errors ='replace')\n",
    "    print(line)\n",
    "    return line\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_dict(data_dict,config):\n",
    "    # when there are more than one entry for each column in the original dictionary\n",
    "    # some of fields might be empty, find the maximum length\n",
    "    max_length_data = 0\n",
    "    for field_name in data_dict:\n",
    "        max_length_data = max(len(data_dict[field_name]),max_length_data)\n",
    "    \n",
    "    # fill the empty cells with default value from config \n",
    "    data_dict = fix_dict(data_dict,config,max_length_data)\n",
    "    \n",
    "    nested_dict = dict.fromkeys([f_name for f_name in config])\n",
    "    new_dict = {str(i):dict(nested_dict) for i in range(max_length_data)}\n",
    "#     print(new_dict)\n",
    "    \n",
    "    for field_name in config:\n",
    "        for idx, val in  enumerate(data_dict[field_name]):\n",
    "            new_dict[str(idx)][field_name]= data_dict[field_name][idx]\n",
    "\n",
    "    for col_name in new_dict:\n",
    "        print(col_name)\n",
    "        new_dict[col_name] = fix_data_type(new_dict[col_name],config)\n",
    "        print(new_dict[col_name])\n",
    "        \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data_dict,config, file_name = 'new_file.txt', encoding = 'cp1252'):\n",
    "    \n",
    "    segregated_dict = break_dict(data_dict,config)\n",
    "    header_line = \"\".join(['{0:{1}}'.format(col_name,int(config[col_name]['length'])) \n",
    "                           for col_name in config])+'\\n'\n",
    "    header_line=header_line.encode(encoding)\n",
    "    with open(file_name,\"wb\") as f:\n",
    "        f.write(header_line)\n",
    "        for dct in segregated_dict:\n",
    "            f.write(make_new_line(segregated_dict[dct],config_dict,encoding = encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'f1': 'â€™', 'f2': 'cd', 'f3': 'ef', 'f4': 'gh', 'f5': 'ij', 'f6': 'kl', 'f7': 'mn', 'f8': 'op', 'f9': 'qr', 'f10': 'st'}\n",
      "1\n",
      "{'f1': 'AB', 'f2': 'CD', 'f3': '123', 'f4': 'GH', 'f5': 'IJ', 'f6': 'KL', 'f7': 'MN', 'f8': 'OP', 'f9': 'QR', 'f10': 'ST'}\n",
      "2\n",
      "{'f1': 'AAABB', 'f2': 'CCC_DDD_D', 'f3': 'EFF', 'f4': 'GH', 'f5': 'IJIJIJIJ', 'f6': 'KL___KL', 'f7': 'MN123456MN', 'f8': 'OPOP', 'f9': 'QRqrQRqr', 'f10': 'STSTstST'}\n",
      "b'\\x92    cd          ef ghij           kl     mn        op           qr                  st           \\n'\n",
      "b'AB   CD          123GHIJ           KL     MN        OP           QR                  ST           \\n'\n",
      "b'AAABBCCC_DDD_D   EFFGHIJIJIJIJ     KL___KLMN123456MNOPOP         QRqrQRqr            STSTstST     \\n'\n"
     ]
    }
   ],
   "source": [
    "write_file(my_data2,config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and Converting to CSV\n",
    "\n",
    "First we open the fwf and read one line. Then we pass the line to chopper to slice the line based on the config file, then the list from chopper is passed down to joiner, which join the cells with delimiter. The new file is written to a (opened) csv file. \n",
    "\n",
    "To avoid memory overload, we read/write line by line (instead of dumping the whole file into local memory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chopper(str_obj, config_dict):\n",
    "    position = 0\n",
    "    chopped_string = []\n",
    "    for config in config_dict.values():\n",
    "        length = int(config['length'])\n",
    "        chopped_string.append(str_obj[position:position + length])\n",
    "        position += length\n",
    "    return chopped_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joiner(chopped_line,delimitor=','):\n",
    "    return delimitor.join(chopped_line)+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwf_2_csv_line(line,config=config_dict,delimitor = ','):\n",
    "    chopped_line = chopper(line,config)\n",
    "    joined_line = joiner(chopped_line,delimitor)\n",
    "    print(joined_line)\n",
    "    return joined_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is encoded in cp1252, but if we wrongfully use utf-8, we see ? for unknown characteres\n",
      "\n",
      "f1   f2          f3 f4f5           f6     f7        f8           f9                  f10          \n",
      "\n",
      "ï¿½    cd          ef ghij           kl     mn        op           qr                  st           \n",
      "\n",
      "AB   CD          123GHIJ           KL     MN        OP           QR                  ST           \n",
      "\n",
      "AAABBCCC_DDD_D   EFFGHIJIJIJIJ     KL___KLMN123456MNOPOP         QRqrQRqr            STSTstST     \n",
      "\n",
      "with correct encoding: \n",
      "\n",
      "f1   ,f2          ,f3 ,f4,f5           ,f6     ,f7        ,f8           ,f9                  ,f10          \n",
      "\n",
      "â€™    ,cd          ,ef ,gh,ij           ,kl     ,mn        ,op           ,qr                  ,st           \n",
      "\n",
      "AB   ,CD          ,123,GH,IJ           ,KL     ,MN        ,OP           ,QR                  ,ST           \n",
      "\n",
      "AAABB,CCC_DDD_D   ,EFF,GH,IJIJIJIJ     ,KL___KL,MN123456MN,OPOP         ,QRqrQRqr            ,STSTstST     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open files, read it, write to new file\n",
    "f_in = open('new_file.txt','r',encoding='cp1252')\n",
    "f_in_2=open('new_file.txt','r',encoding='utf-8',errors='replace')\n",
    "f_out = open('new_utf8_file.csv','w',encoding='utf-8')\n",
    "\n",
    "# Showing that with wrong encoding, the file can't be read\n",
    "print('file is encoded in cp1252, but if we wrongfully use utf-8, we see ? for unknown characteres\\n')\n",
    "for line in f_in_2:\n",
    "    print(line)\n",
    "\n",
    "print('with correct encoding: \\n')\n",
    "for line in f_in:\n",
    "    comma_joined_line = fwf_2_csv_line(line)\n",
    "    f_out.write(comma_joined_line)\n",
    "f_in.close()\n",
    "f_in_2.close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1   ,f2          ,f3 ,f4,f5           ,f6     ,f7        ,f8           ,f9                  ,f10          \n",
      "\n",
      "â€™    ,cd          ,ef ,gh,ij           ,kl     ,mn        ,op           ,qr                  ,st           \n",
      "\n",
      "AB   ,CD          ,123,GH,IJ           ,KL     ,MN        ,OP           ,QR                  ,ST           \n",
      "\n",
      "AAABB,CCC_DDD_D   ,EFF,GH,IJIJIJIJ     ,KL___KL,MN123456MN,OPOP         ,QRqrQRqr            ,STSTstST     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The csv file is encoded in utf-8\n",
    "with open('new_utf8_file.csv','r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Because the file is encoded with utf-8 and Microsoft Excel uses cp1252, it might not show the file correctly for some of the entries (not normal characters, but the ones that binary encoding in utf-8 and cp1252 are different like ' â€™ ').\n",
    "\n",
    "This code works fine with small objects, but for bigger files, the process of reading file line by line and writting to new file may be inconviniently time consuming. For such files, it's better to use PySpark to use the multiprocessing capabilities. \n",
    "\n",
    "Because no external libraries has been used for this code, using docker didn't seem to be of any help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
